---
title: "Getting_the_Most_out_of_Models"
author: "Z.CAI"
date: "2022年1月17日"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Advanced architecture patterns

batch normalisation
```{r}
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)
```

the layer_batch_normalisation layer is typically used after a convolutional or densely connected layer
```{r}
layer_conv_2d(filters = 32, kernel_size = 3, activation = "relu") %>% 
layer_batch_normalization()
layer_dense(units = 32, ,activation = "relu") %>% 
layer_batch_normalization()
```

example of building a lightwieght, depthwise separable convnet for an image-classification task(softmax categorical classification) on a small dataset
```{r}
library(keras)

height <- 64
width <- 64
channels <- 3
num_classes <- 10

model <- keras_model_sequential() %>% 
  layer_separable_conv_2d(filters = 32, kernel_size = 3, 
                          activation = "relu",
                          input_shape = c(height, width, channels)) %>% 
  layer_separable_conv_2d(filters = 64, kernel_size = 3,
                          activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = 2) %>% 
  
  layer_separable_conv_2d(filters = 64, kernel_size = 3, 
                          activation = "relu") %>% 
  layer_separable_conv_2d(filters = 128, kernel_size = 3,
                          activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = 2) %>% 
  
  layer_separable_conv_2d(filters = 64, kernel_size = 3, 
                          activation = "relu") %>% 
  layer_separable_conv_2d(filters = 128, kernel_size = 3, 
                          activation = "relu") %>% 
  
  layer_global_average_pooling_2d() %>% 
  
  layer_dense(units = 32, activation = "relu") %>% 
  
  layer_dense(units = num_classes, activation = "sotfmax")

model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy"
)
```

## Hyperparameter optimisation

## Model ensembling

preds_a <- model_a %>% predict(x_val)
preds_b <- model_b %>% predict(x_val)
preds_c <- model_c %>% predict(x_val)
preds_d <- model_d %>% predict(x_val)
final_preds <- 0.25 * (preds_a + preds_b + preds_c + preds_d)



































