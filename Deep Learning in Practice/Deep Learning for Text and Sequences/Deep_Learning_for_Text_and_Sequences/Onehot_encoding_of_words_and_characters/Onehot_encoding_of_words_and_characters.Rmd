---
title: "Onehot_encoding_of_words_and_characters"
author: "Z.CAI"
date: "2021/12/22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# One-Hot Encoding of Words and Characters


## warning: input string 1 is invalid in this locale
```{r}
Sys.setlocale('LC_CTYPE','C')
```

word-level one-hot encoding
```{r}
samples <-c("The LSE applications have not been successful.", 
            "The Oxford and the Cambridge are still under review.")

token_index <- list()
for (sample in samples)
  for (word in strsplit(sample, "")[[1]])
    if (!word %in% names(token_index))
      token_index[[word]] <- length(token_index) + 2

max_length <-10

results <- array(0, dim = c(length(samples),
                            max_length,
                            max(as.integer(token_index))))

for (i in 1:length(samples)) {
  sample <- samples[[i]]
  words <- head(strsplit(sample, "")[[1]], n = max_length)
  for (j in 1:length(words)) {
    index <- token_index[[words[[j]]]]
    results[[i, j, index]] <- 1
  }
}
```

using keras for word-level one-hot encoding
```{r}
library(keras)

samples <-c("The LSE applications have not been successful.", 
            "The Oxford and the Cambridge are still under review.")

tokenizer <- text_tokenizer(num_words = 1000) %>% 
  fit_text_tokenizer(samples)

sequences <- texts_to_sequences(tokenizer, samples)

one_hot_results <- texts_to_matrix(tokenizer, samples, mode = "binary")

word_index <- tokenizer$word_index

cat("Found", length(word_index), "unique token.\n")
```

word-level one-hot encoding with hasing trick 
```{r}
library(digest)

samples <-c("The LSE applications have not been successful", 
            "The Oxford and the Cambridge are still under review")

dimensionality <- 1000

max_length <- 10

hex_to_int = function(h) {
  xx = strsplit(tolower(h), "")[[1L]]
  pos = match(xx, c(0L:9L, letters[1L:6L]))
  sum((pos - 1L) * 16^(rev(seq_along(xx) - 1)))
}

results <- array(0, dim = c(length(samples), max_length, dimensionality))

for (i in 1:length(samples)){
  sample <- samples[[i]]
  words <- head(strsplit(sample, " ")[[1]], n = max_length)
  for (j in 1:length(words)){
    index <- hex_to_int(digest(words[[j]], algo = c("crc32"))) %% dimensionality
    results[[i, j, index]] <- 1
  }
}

results[,,651]
```

the "crc32" limits the length of hash function output for better computation, while the 'strtoi' functions limits the compularity from "characters" to "integer", so 'hex_to_int' is defined by hand to replace 'strtoi'. then transfer the hash output to numbers.





















